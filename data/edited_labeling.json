{
    "entity_pair": "deep feedforward network * feedforward neural network",
    "seen_with": [
        ", also often called"
    ],
    "label": "P460"
}
{
    "entity_pair": "multilay perceptron * deep learn",
    "seen_with": [
        "( MLPs ) , are the quintessential"
    ],
    "label": "P31"
}
{
    "entity_pair": "feedforward network * function",
    "seen_with": [
        "is to approximate some"
    ],
    "label": "P366"
}
{
    "entity_pair": "feedforward network * map",
    "seen_with": [
        "defines a"
    ],
    "label": "P31"
}
{
    "entity_pair": "paramet * function approxim",
    "seen_with": [
        "\u03b8 that result in the best"
    ],
    "label": "P1552"
}
{
    "entity_pair": "inform * function",
    "seen_with": [
        "flows through the"
    ],
    "label": "P31"
}
{
    "entity_pair": "feedforward neural network * recurr neural network",
    "seen_with": [
        "are extended to include feedback connections , they are called"
    ],
    "label": "P1889"
}
{
    "entity_pair": "feedforward network * machin learn",
    "seen_with": [
        "are of extreme importance to"
    ],
    "label": "P279"
}
{
    "entity_pair": "convolut network * object recognit",
    "seen_with": [
        "used for"
    ],
    "label": "P366"
}
{
    "entity_pair": "feedforward network * recurr network",
    "seen_with": [
        "are a conceptual stepping stone on the path to"
    ],
    "label": "P1889"
}
{
    "entity_pair": "layer * feedforward network",
    "seen_with": [
        "of a"
    ],
    "label": "P361"
}
{
    "entity_pair": "layer * train data",
    "seen_with": [
        "is not directly specified by the"
    ],
    "label": "P1889"
}
{
    "entity_pair": "learn algorithm * layer",
    "seen_with": [
        "must decide how to use these",
        "must decide how to use those"
    ],
    "label": "P2283"
}
{
    "entity_pair": "train data * layer",
    "seen_with": [
        "does not say what each individual",
        "does not show the desired output for each of these"
    ],
    "label": "P1889"
}
{
    "entity_pair": "layer * hidden layer",
    "seen_with": [
        "are called"
    ],
    "label": "P1552"
}
{
    "entity_pair": "hidden layer * vector",
    "seen_with": [
        "of the network is typically"
    ],
    "label": "P31"
}
{
    "entity_pair": "layer * function",
    "seen_with": [
        "as representing a single vector-to-vector"
    ],
    "label": "P31"
}
{
    "entity_pair": "layer * unit",
    "seen_with": [
        "as consisting of many"
    ],
    "label": "P527"
}
{
    "entity_pair": "feedforward network * gener",
    "seen_with": [
        "as function approximation machines that are designed to achieve statistical"
    ],
    "label": "P1552"
}
{
    "entity_pair": "feedforward network * linear model",
    "seen_with": [
        "requires making many of the same design decisions as are necessary for a",
        "is to begin with"
    ],
    "label": "P1889"
}
{
    "entity_pair": "linear model * logist regress",
    "seen_with": [
        ", such as"
    ],
    "label": "P1552"
}
{
    "entity_pair": "logist regress * linear regress",
    "seen_with": [
        "and"
    ],
    "label": "P1889"
}
{
    "entity_pair": "linear model * function",
    "seen_with": [
        "also have the obvious defect that the model capacity is limited to linear",
        "can not implement such a",
        "is not able to represent the XOR",
        "to represent nonlinear",
        "can now describe the"
    ],
    "label": "P31"
}
{
    "entity_pair": "kernel trick * learn algorithm",
    "seen_with": [
        "described in section 5.7.2 , to obtain a nonlinear"
    ],
    "label": "P366"
}
{
    "entity_pair": "learn algorithm * map",
    "seen_with": [
        "based on implicitly applying the \u03c6"
    ],
    "label": "P279"
}
{
    "entity_pair": "gener * set",
    "seen_with": [
        "to the test"
    ],
    "label": "P279"
}
{
    "entity_pair": "paramet * function",
    "seen_with": [
        "\u03b8 that we use to learn \u03c6 from a broad class of",
        ", followed by a fixed , nonlinear"
    ],
    "label": "P366"
}
{
    "entity_pair": "deep feedforward network * hidden layer",
    "seen_with": [
        ", with \u03c6 defining a"
    ],
    "label": "P527"
}
{
    "entity_pair": "human * gener",
    "seen_with": [
        "practitioners can encode their knowledge to help"
    ],
    "label": "P2283"
}
{
    "entity_pair": "feedforward network * hidden layer",
    "seen_with": [
        "with one",
        "have introduced the concept of a"
    ],
    "label": "P527"
}
{
    "entity_pair": "activ function * hidden layer",
    "seen_with": [
        "that will be used to compute the"
    ],
    "label": "P366"
}
{
    "entity_pair": "unit * layer",
    "seen_with": [
        "should be in each"
    ],
    "label": "P361"
}
{
    "entity_pair": "deep neural network * gradient",
    "seen_with": [
        "requires computing the"
    ],
    "label": "P2283"
}
{
    "entity_pair": "function * oper",
    "seen_with": [
        "( `` exclusive or '' ) is an"
    ],
    "label": "P279"
}
{
    "entity_pair": "learn algorithm * paramet",
    "seen_with": [
        "will adapt the"
    ],
    "label": "P2283"
}
{
    "entity_pair": "hidden layer * hidden unit",
    "seen_with": [
        "containing two"
    ],
    "label": "P527"
}
{
    "entity_pair": "feedforward network * hidden unit",
    "seen_with": [
        "has a vector of"
    ],
    "label": "P527"
}
{
    "entity_pair": "hidden unit * function",
    "seen_with": [
        "h that are computed by a"
    ],
    "label": "P366"
}
{
    "entity_pair": "hidden unit * layer",
    "seen_with": [
        "are then used as the input for a second"
    ],
    "label": "P361"
}
{
    "entity_pair": "layer * output layer",
    "seen_with": [
        "is the"
    ],
    "label": "P31"
}
{
    "entity_pair": "output layer * linear regress",
    "seen_with": [
        "is still just a"
    ],
    "label": "P31"
}
{
    "entity_pair": "feedforward network * linear function",
    "seen_with": [
        "as a whole would remain a"
    ],
    "label": "P279"
}
{
    "entity_pair": "neural network * transform",
    "seen_with": [
        "do so using an affine"
    ],
    "label": "P2283"
}
{
    "entity_pair": "transform * paramet",
    "seen_with": [
        "controlled by learned"
    ],
    "label": "P2283"
}
{
    "entity_pair": "function * activ function",
    "seen_with": [
        "called an"
    ],
    "label": "P527"
}
{
    "entity_pair": "weight * transform",
    "seen_with": [
        "of a linear"
    ],
    "label": "P361"
}
{
    "entity_pair": "linear model * coeffici",
    "seen_with": [
        "must apply a fixed",
        "therefore can not use the value of x 1 to change the"
    ],
    "label": "P527"
}
{
    "entity_pair": "weight * bia",
    "seen_with": [
        "and a scalar"
    ],
    "label": "P1889"
}
{
    "entity_pair": "paramet * transform",
    "seen_with": [
        "to describe an affine"
    ],
    "label": "P361"
}
{
    "entity_pair": "transform * vector",
    "seen_with": [
        "from a"
    ],
    "label": "P279"
}
{
    "entity_pair": "activ function * function",
    "seen_with": [
        "g is typically chosen to be a"
    ],
    "label": "P31"
}
{
    "entity_pair": "neural network * relu",
    "seen_with": [
        ", the default recommendation is to use the rectified linear unit or"
    ],
    "label": "P2283"
}
{
    "entity_pair": "neural network * matrix",
    "seen_with": [
        "is to multiply the input"
    ],
    "label": "P366"
}
{
    "entity_pair": "layer * matrix",
    "seen_with": [
        "\u2019 s weight"
    ],
    "label": "P31"
}
{
    "entity_pair": "converg * gradient descent",
    "seen_with": [
        "point of"
    ],
    "label": "P361"
}
{
    "entity_pair": "gradient descent * paramet",
    "seen_with": [
        "depends on the initial values of the"
    ],
    "label": "P527"
}
{
    "entity_pair": "neural network * machin learn",
    "seen_with": [
        "is not much different from training any other"
    ],
    "label": "P279"
}
{
    "entity_pair": "algorithm * optim procedur",
    "seen_with": [
        "by specifying an"
    ],
    "label": "P527"
}
{
    "entity_pair": "neural network * loss function",
    "seen_with": [
        "causes most interesting"
    ],
    "label": "P1552"
}
{
    "entity_pair": "convex optim * paramet",
    "seen_with": [
        "converges starting from any initial"
    ],
    "label": "P366"
}
{
    "entity_pair": "stochast gradient descent * loss function",
    "seen_with": [
        "applied to non-convex"
    ],
    "label": "P366"
}
{
    "entity_pair": "feedforward neural network * weight",
    "seen_with": [
        ", it is important to initialize all"
    ],
    "label": "P527"
}
{
    "entity_pair": "optim algorithm * feedforward network",
    "seen_with": [
        "used to train"
    ],
    "label": "P366"
}
{
    "entity_pair": "algorithm * gradient",
    "seen_with": [
        "is almost always based on using the"
    ],
    "label": "P2283"
}
{
    "entity_pair": "gradient * cost function",
    "seen_with": [
        "of the",
        "to descend the"
    ],
    "label": "P361"
}
{
    "entity_pair": "algorithm * gradient descent",
    "seen_with": [
        "are improvements and refinements on the ideas of"
    ],
    "label": "P31"
}
{
    "entity_pair": "linear regress * support vector machin",
    "seen_with": [
        "and"
    ],
    "label": "P1889"
}
{
    "entity_pair": "gradient * neural network",
    "seen_with": [
        "is slightly more complicated for a"
    ],
    "label": "P361"
}
{
    "entity_pair": "gradient * back-propag",
    "seen_with": [
        "using the"
    ],
    "label": "P366"
}
{
    "entity_pair": "machin learn * cost function",
    "seen_with": [
        "models , to apply gradient-based learning we must choose a"
    ],
    "label": "P2283"
}
{
    "entity_pair": "cost function * neural network",
    "seen_with": [
        "used to train a",
        "for"
    ],
    "label": "P361"
}
{
    "entity_pair": "parametr model * linear model",
    "seen_with": [
        ", such as"
    ],
    "label": "P366"
}
{
    "entity_pair": "parametr model * distribut",
    "seen_with": [
        "defines a"
    ],
    "label": "P279"
}
{
    "entity_pair": "cross-entropi * train data",
    "seen_with": [
        "between the"
    ],
    "label": "P1889"
}
{
    "entity_pair": "cost function * regular",
    "seen_with": [
        "described here with a"
    ],
    "label": "P1552"
}
{
    "entity_pair": "regular * linear model",
    "seen_with": [
        "applied to"
    ],
    "label": "P366"
}
{
    "entity_pair": "weight decay * linear model",
    "seen_with": [
        "approach used for"
    ],
    "label": "P366"
}
{
    "entity_pair": "regular * neural network",
    "seen_with": [
        "strategies for"
    ],
    "label": "P366"
}
{
    "entity_pair": "neural network * maximum likelihood",
    "seen_with": [
        "are trained using"
    ],
    "label": "P2283"
}
{
    "entity_pair": "cost function * cross-entropi",
    "seen_with": [
        "is simply the negative log-likelihood , equivalently described as the"
    ],
    "label": "P460"
}
{
    "entity_pair": "varianc * gaussian distribut",
    "seen_with": [
        "of the"
    ],
    "label": "P361"
}
{
    "entity_pair": "maximum likelihood estim * distribut",
    "seen_with": [
        "with an output"
    ],
    "label": "P366"
}
{
    "entity_pair": "cost function * learn algorithm",
    "seen_with": [
        "must be large and predictable enough to serve as a good guide for the"
    ],
    "label": "P361"
}
{
    "entity_pair": "cross-entropi * maximum likelihood estim",
    "seen_with": [
        "cost used to perform"
    ],
    "label": "P366"
}
{
    "entity_pair": "neural network * function",
    "seen_with": [
        "as being able to represent any"
    ],
    "label": "P279"
}
{
    "entity_pair": "cost function * function",
    "seen_with": [
        "as being a functional rather than just a"
    ],
    "label": "P31"
}
{
    "entity_pair": "function * map",
    "seen_with": [
        "is a"
    ],
    "label": "P279"
}
{
    "entity_pair": "function * paramet",
    "seen_with": [
        "rather than merely choosing a set of"
    ],
    "label": "P527"
}
{
    "entity_pair": "function * calculu of variat",
    "seen_with": [
        "requires a mathematical tool called"
    ],
    "label": "P2283"
}
{
    "entity_pair": "mean squar error * optim",
    "seen_with": [
        "and mean absolute error often lead to poor results when used with gradient-based"
    ],
    "label": "P366"
}
{
    "entity_pair": "unit * gradient",
    "seen_with": [
        "that saturate produce very small"
    ],
    "label": "P1552"
}
{
    "entity_pair": "cross-entropi * mean squar error",
    "seen_with": [
        "cost function is more popular than"
    ],
    "label": "P1889"
}
{
    "entity_pair": "cost function * unit",
    "seen_with": [
        "is tightly coupled with the choice of output"
    ],
    "label": "P2283"
}
{
    "entity_pair": "output layer * transform",
    "seen_with": [
        "is then to provide some additional"
    ],
    "label": "P2283"
}
{
    "entity_pair": "unit * transform",
    "seen_with": [
        "is an output unit based on an affine"
    ],
    "label": "P2283"
}
{
    "entity_pair": "unit * vector",
    "seen_with": [
        "produces a"
    ],
    "label": "P1552"
}
{
    "entity_pair": "output layer * gaussian distribut",
    "seen_with": [
        "are often used to produce the mean of a conditional"
    ],
    "label": "P366"
}
{
    "entity_pair": "maximum likelihood * covari",
    "seen_with": [
        "framework makes it straightforward to learn the"
    ],
    "label": "P366"
}
{
    "entity_pair": "covari * function",
    "seen_with": [
        "of the Gaussian be a"
    ],
    "label": "P31"
}
{
    "entity_pair": "covari * matrix",
    "seen_with": [
        "must be constrained to be a positive definite"
    ],
    "label": "P31"
}